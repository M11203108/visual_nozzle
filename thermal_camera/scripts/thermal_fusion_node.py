#!/usr/bin/env python3
import rclpy
from rclpy.node import Node
from std_msgs.msg import Float32MultiArray
from sensor_msgs.msg import Image
from geometry_msgs.msg import Point
from cv_bridge import CvBridge
import numpy as np
import cv2
import pyrealsense2 as rs
import os

class ThermalFusionNode(Node):
    def __init__(self):
        super().__init__('thermal_fusion_node')
        self.bridge = CvBridge()

        # è¼‰å…¥ Homography
        self.H = np.load('/home/robot/newjasmine_ws/src/thermal_camera/scripts/H_avg.npy')
        self.get_logger().info("âœ… å·²è¼‰å…¥ H_avg.npy")
        # è¼‰å…¥èª¤å·®åœ–
        self.error_map = np.load('/home/robot/newjasmine_ws/src/thermal_camera/scripts/dual_calib_20250628_123046/H_error_map.npy')

        # åˆå§‹åŒ– RealSense
        self.pipeline = rs.pipeline()
        config = rs.config()
        config.enable_stream(rs.stream.color, 1280, 720, rs.format.bgr8, 30)
        config.enable_stream(rs.stream.depth, 1280, 720, rs.format.z16, 30)
        self.pipeline.start(config)
        self.align = rs.align(rs.stream.color)

        self.intrinsics = None
        self.depth_scale = None

        # è¨‚é–±ç†±åƒå„€æœ€å¤§æº«åº¦é»
        self.create_subscription(Float32MultiArray, '/thermal_max_temp', self.thermal_callback, 10)

        # è¨‚é–±ç†±åƒå„€ç•«é¢
        self.create_subscription(Image, '/ir_camera/image', self.thermal_image_callback, 10)
        self.thermal_img = None

        # ç™¼ä½ˆç«æºç©ºé–“åº§æ¨™
        self.fire_pub = self.create_publisher(Point, '/thermal_fire_position', 10)

        # å»ºç«‹è¦–çª—
        for name in [
            "Overlay (Thermal + RGB)",
            "Thermal Warped",
            "Thermal Raw (gray)",
            "RealSense RGB",
            "RealSense Depth"
        ]:
            cv2.namedWindow(name, cv2.WINDOW_NORMAL)

    def thermal_image_callback(self, msg):
        self.thermal_img = self.bridge.imgmsg_to_cv2(msg, desired_encoding='mono8')

    def thermal_callback(self, msg):
        if len(msg.data) < 7:
            self.get_logger().warn("âš ï¸ ç†±åƒå„€è³‡æ–™ä¸å®Œæ•´ï¼Œéœ€åŒ…å« [tx, ty, temp, xmin, xmax, ymin, ymax]")
            return

        tx, ty, temp, xmin, xmax, ymin, ymax = msg.data
        tx, ty = int(tx), int(ty)

        # === å– RealSense ç•«é¢ ===
        frames = self.pipeline.wait_for_frames()
        aligned_frames = self.align.process(frames)
        color_frame = aligned_frames.get_color_frame()
        depth_frame = aligned_frames.get_depth_frame()

        if not color_frame or not depth_frame or self.thermal_img is None:
            return

        color_image = np.asanyarray(color_frame.get_data())
        depth_image = np.asanyarray(depth_frame.get_data())

        if self.intrinsics is None:
            self.intrinsics = color_frame.profile.as_video_stream_profile().get_intrinsics()
            self.depth_scale = depth_frame.get_units()

        # === Homography å°æ‡‰ç†±åƒå„€é»åˆ° RGB ä¸Š ===
        pt_src = np.array([[tx, ty]], dtype='float32')
        pt_dst = cv2.perspectiveTransform(pt_src[None], self.H)[0][0]
        x_rs, y_rs = int(pt_dst[0]), int(pt_dst[1])

        if not (0 <= x_rs < depth_image.shape[1] and 0 <= y_rs < depth_image.shape[0]):
            self.get_logger().warn("ğŸ”¥ å°æ‡‰é»è¶…å‡ºç¯„åœ")
            return

        depth_val = depth_image[y_rs, x_rs] * self.depth_scale
        if depth_val == 0:
            self.get_logger().warn("ğŸ“­ å°æ‡‰é»æ·±åº¦ç‚º 0ï¼Œè·³é")
            return

        # === è¨ˆç®—å°æ‡‰çš„ 3D åº§æ¨™ ===
        X, Y, Z = rs.rs2_deproject_pixel_to_point(self.intrinsics, [x_rs, y_rs], depth_val)

        fire_point = Point()
        fire_point.x = Z
        fire_point.y = -X
        fire_point.z = -Y
        self.fire_pub.publish(fire_point)
        self.get_logger().info(f'ğŸ”¥ ç†±åƒç«æºæ·±åº¦åº§æ¨™: ({fire_point.x:.2f}, {fire_point.y:.2f}, {fire_point.z:.2f}) m')

        # === å°é½Šç†±åƒå„€å½±åƒ + ä¸Šè‰² ===
        aligned_thermal = cv2.warpPerspective(self.thermal_img, self.H, 
                                            (color_image.shape[1], color_image.shape[0]))
        thermal_color = cv2.applyColorMap(aligned_thermal, cv2.COLORMAP_JET)

        # === ç–ŠåŠ ç•«é¢ ===
        overlay = cv2.addWeighted(color_image, 0.6, thermal_color, 0.4, 0)
        cv2.circle(overlay, (x_rs, y_rs), 8, (0, 0, 255), 2)
        cv2.putText(overlay, f"{temp:.1f}C", (x_rs + 10, y_rs - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)


        # # ğŸ”² åŠ ä¸Šç´…æ¡†ï¼ˆç†±å€ï¼‰
        # x1, y1 = int(msg.data[3]), int(msg.data[4])
        # x2, y2 = int(msg.data[5]), int(msg.data[6])

        # # å¥—ç”¨ Homography åˆ°å…©å€‹è§’é»
        # p1 = cv2.perspectiveTransform(np.array([[[x1, y1]]], dtype=np.float32), self.H)[0][0]
        # p2 = cv2.perspectiveTransform(np.array([[[x2, y2]]], dtype=np.float32), self.H)[0][0]
        # pt1 = (int(p1[0]), int(p1[1]))
        # pt2 = (int(p2[0]), int(p2[1]))

        # cv2.rectangle(overlay, pt1, pt2, (0, 0, 255), 2)

        # ğŸ”² åŠ ä¸Šç´…æ¡†ï¼ˆç†±å€ï¼‰
        x1, y1 = int(msg.data[3]), int(msg.data[5])  # xmin, ymin
        x2, y2 = int(msg.data[4]), int(msg.data[6])  # xmax, ymax

        # æŸ¥è©¢è©²å€ç†±é»çš„èª¤å·®å€¼ï¼Œè‹¥è¶…å‡ºå°±ä½¿ç”¨å¹³å‡èª¤å·®
        try:
            error = self.error_map[ty, tx]  # æ³¨æ„æ˜¯ [y, x]
        except IndexError:
            error = 15.0  # fallback

        # æ”¾å¤§æ¯”ä¾‹å› å­ï¼ˆæ ¹æ“šèª¤å·®æ±ºå®šï¼Œå¯å¾®èª¿ï¼‰
        scale = 1.0 + (error / 20.0)  # ä¾‹å¦‚èª¤å·®20 â†’ æ”¾å¤§2å€

        # è¨ˆç®—ä¸­å¿ƒé»èˆ‡æ”¾å¤§å¾Œçš„æ–°åº§æ¨™
        cx = (x1 + x2) / 2.0
        cy = (y1 + y2) / 2.0
        w = (x2 - x1) * scale
        h = (y2 - y1) * scale
        x1s = int(cx - w / 2)
        y1s = int(cy - h / 2)
        x2s = int(cx + w / 2)
        y2s = int(cy + h / 2)

        # å¥—ç”¨ Homography
        p1 = cv2.perspectiveTransform(np.array([[[x1s, y1s]]], dtype=np.float32), self.H)[0][0]
        p2 = cv2.perspectiveTransform(np.array([[[x2s, y2s]]], dtype=np.float32), self.H)[0][0]
        pt1 = (int(p1[0]), int(p1[1]))
        pt2 = (int(p2[0]), int(p2[1]))

        cv2.rectangle(overlay, pt1, pt2, (0, 0, 255), 2)


        # === æ·±åº¦åœ–å½©è‰²åŒ– ===
        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)

        # === é¡¯ç¤ºæ‰€æœ‰ç•«é¢ ===
        cv2.imshow("Overlay (Thermal + RGB)", overlay)
        cv2.imshow("Thermal Warped", thermal_color)
        cv2.imshow("Thermal Raw (gray)", self.thermal_img)
        cv2.imshow("RealSense RGB", color_image)
        cv2.imshow("RealSense Depth", depth_colormap)
        cv2.waitKey(1)


def main(args=None):
    rclpy.init(args=args)
    node = ThermalFusionNode()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.pipeline.stop()
        node.destroy_node()
        rclpy.shutdown()
        cv2.destroyAllWindows()

if __name__ == '__main__':
    main()
